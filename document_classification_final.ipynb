{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from augraphy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# training config\n",
    "# img_size = 256\n",
    "LR = 5e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 0\n",
    "pretrained_size = 380"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    # A.Resize(height=pretrained_size, width=pretrained_size),\n",
    "    A.LongestMaxSize(max_size=pretrained_size, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "aug_test_transform = A.Compose([    \n",
    "    A.RandomRotate90(),\n",
    "    A.Flip(p=0.5),              \n",
    "                        \n",
    "    # A.Resize(height=pretrained_size, width=pretrained_size),\n",
    "    A.LongestMaxSize(max_size=pretrained_size, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=pretrained_size, min_width=pretrained_size, border_mode=0, value=(255, 255, 255)),\n",
    "    \n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 정의\n",
    "trn_dataset = ImageDataset(\n",
    "    \"/data/ephemeral/home/data/augmentation/[12_v5_40배][0807]train_aug.csv\",\n",
    "    \"/data/ephemeral/home/data/augmentation/[12_v5_40배][0807]train_aug/\",\n",
    "    transform=trn_transform\n",
    ")\n",
    "tst_dataset = ImageDataset(\n",
    "    \"/data/ephemeral/home/data/sample_submission.csv\",\n",
    "    \"/data/ephemeral/home/data/test/\",\n",
    "    transform=tst_transform\n",
    ")\n",
    "aug_test_dataset = ImageDataset(\n",
    "    \"/data/ephemeral/home/data/sample_submission.csv\",\n",
    "    \"/data/ephemeral/home/data/test/\",\n",
    "    transform=aug_test_transform\n",
    ")\n",
    "print(len(trn_dataset), len(tst_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 정의\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "aug_test_dataloader = DataLoader(\n",
    "    aug_test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        preds = model(image)\n",
    "        loss = loss_fn(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['efficientnet_b2', 'resnext50_32x4d', 'mobilenetv2_100', 'efficientnet_b3', 'efficientnet_b4']\n",
    "\n",
    "base_path = '/data/ephemeral/home/code/model_softvoting/[v12]aug5증강_모델'\n",
    "model_paths = [os.path.join(base_path, f\"{model_name}.pth\") for model_name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model_path in zip(model_names, model_paths):\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        ret = training(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "        ret['epoch'] = epoch + 1\n",
    "\n",
    "        log = \"\"\n",
    "        for k, v in ret.items():\n",
    "            log += f\"{k}: {v:.4f}\\n\"\n",
    "        print(log)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['efficientnet_b2', 'resnext50_32x4d', 'mobilenetv2_100', 'mobilenetv3_large_100', 'efficientnet_b4']\n",
    "\n",
    "base_path = '/data/ephemeral/home/code/model_softvoting/[v11]aug5적용_모델'\n",
    "model_paths = [os.path.join(base_path, f\"{model_name}.pth\") for model_name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "for model_name, model_path in zip(model_names, model_paths):\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        ret = training(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "        ret['epoch'] = epoch + 1\n",
    "\n",
    "        log = \"\"\n",
    "        for k, v in ret.items():\n",
    "            log += f\"{k}: {v:.4f}\\n\"\n",
    "        print(log)\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 제출 모델 inference\n",
    "model_names = ['resnext50_32x4d', 'efficientnet_b3', 'resnext50_32x4d', 'efficientnet_b2', 'mobilenetv2_100', 'resnext50_32x4d']\n",
    "\n",
    "model_paths = [\n",
    "    '/data/ephemeral/home/code/model_softvoting/[v12]aug5증강_모델/resnext50_32x4d.pth',\n",
    "    '/data/ephemeral/home/code/model_softvoting/[v12]aug5증강_모델/efficientnet_b3.pth',\n",
    "    '/data/ephemeral/home/code/model_softvoting/[v11]aug5적용_모델/resnext50_32x4d.pth',\n",
    "    '/data/ephemeral/home/code/model_softvoting/[v11]aug5적용_모델/efficientnet_b2.pth',\n",
    "    '/data/ephemeral/home/code/model_softvoting/[v11]aug5적용_모델/mobilenetv2_100.pth',\n",
    "    '/data/ephemeral/home/code/model_softvoting/resnext50_32x4d_sungmi.pth'\n",
    "]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 설정\n",
    "N_TTA = 20\n",
    "\n",
    "# 각 모델의 예측 확률값을 저장할 리스트\n",
    "all_model_preds = []\n",
    "\n",
    "# 모델을 불러와서 예측 수행\n",
    "for model_name, model_path in zip(model_names, model_paths):\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    \n",
    "    #preds_list = []\n",
    "    model_preds = []\n",
    "    with torch.no_grad():\n",
    "        loaders = [tst_loader] + [aug_test_dataloader] * N_TTA\n",
    "\n",
    "        for batches in tqdm(zip(*loaders), total=len(tst_loader)):\n",
    "            images, *aug_images = [images.to(device) for images, _ in batches]\n",
    "\n",
    "            outputs_original = model(images)\n",
    "            outputs_augmented = [model(aug_image) for aug_image in aug_images]\n",
    "\n",
    "            final_outputs = (outputs_original + sum(outputs_augmented)) / (N_TTA + 1)\n",
    "            #preds_list.extend(final_outputs.argmax(dim=1).cpu().numpy())\n",
    "            model_preds.append(final_outputs.cpu().numpy())\n",
    "    \n",
    "    all_model_preds.append(np.concatenate(model_preds))\n",
    "\n",
    "    # 예측 결과 저장\n",
    "    #En_pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "    #En_pred_df['target'] = preds_list\n",
    "\n",
    "    #sample_submission_df = pd.read_csv('/data/ephemeral/home/data/sample_submission.csv')\n",
    "    #assert (sample_submission_df['ID'] == En_pred_df['ID']).all()\n",
    "\n",
    "    #output_path = f'/data/ephemeral/home/code/pred/[0807]test_aug_v11/[0807]TTA10_augv5_v11_testaug_soft_pred_{model_name}.csv'\n",
    "    #En_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# 소프트 보팅을 통한 최종 예측 생성\n",
    "softvoting_preds = np.mean(all_model_preds, axis=0)\n",
    "final_preds = np.argmax(softvoting_preds, axis=1)\n",
    "\n",
    "# 예측 결과 확인\n",
    "# print(\"Ensemble Predictions:\", final_preds)\n",
    "\n",
    "En_pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "En_pred_df['target'] = final_preds\n",
    "\n",
    "sample_submission_df = pd.read_csv('/data/ephemeral/home/data/sample_submission.csv')\n",
    "assert (sample_submission_df['ID'] == En_pred_df['ID']).all()\n",
    "\n",
    "En_pred_df.to_csv('/data/ephemeral/home/code/pred/[0808]test_aug_v12/[0810]vv4_tta20_2model_total_testaug_soft_pred.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved for all models and ensemble.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
