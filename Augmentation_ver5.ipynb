{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from augraphy import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torchvision.transforms.functional as TF\n",
    "from PIL import Image\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_resize_and_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_resize_and_shift(image, original_size, shift_limit=0.1, scale_min=-0.3, scale_max=0.3):\n",
    "    h, w = original_size\n",
    "    img_h, img_w = image.shape[:2]\n",
    "\n",
    "    # 가로 세로 비율 맞추기\n",
    "    scale_factor = random.uniform(scale_min, scale_max)\n",
    "    new_w, new_h = int(img_w * (1 + scale_factor)), int(img_h * (1 + scale_factor))\n",
    "\n",
    "    # shift 범위 계산\n",
    "    max_shift_x = min(int(shift_limit * w), new_w - w)\n",
    "    max_shift_y = min(int(shift_limit * h), new_h - h)\n",
    "    shift_x = random.randint(-max_shift_x, max_shift_x) if max_shift_x > 0 else 0\n",
    "    shift_y = random.randint(-max_shift_y, max_shift_y) if max_shift_y > 0 else 0\n",
    "\n",
    "    # Albumentations 변환기 정의\n",
    "    transform = A.Compose([\n",
    "        A.Resize(new_h, new_w, interpolation=cv2.INTER_LINEAR),\n",
    "        A.Affine(translate_px={\"x\": shift_x, \"y\": shift_y}, mode=cv2.BORDER_CONSTANT, cval=(255, 255, 255)),\n",
    "        A.PadIfNeeded(min_height=h, min_width=w, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "    ], p=1)\n",
    "\n",
    "    # Albumentations 변환 적용\n",
    "    augmented = transform(image=image)\n",
    "    padded_image = augmented['image']\n",
    "\n",
    "    # 최종 크기 맞추기\n",
    "    final_image = cv2.resize(padded_image, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# original_size 정의 \n",
    "original_size = image.shape[:2]  # (height, width)\n",
    "\n",
    "# 이전에 작성한 코드와 동일하게 이미지 변환\n",
    "transformed_image = pad_resize_and_shift(image, original_size)\n",
    "\n",
    "# BGR -> RGB로 변환\n",
    "transformed_image_rgb = cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(transformed_image_rgb)\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## apply_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로테이션 함수 정의\n",
    "def apply_rotation(image, angle_min=0, angle_max=360):\n",
    "    h, w = image.shape[:2]\n",
    "    transform = A.Compose([\n",
    "        A.Rotate(limit=(angle_min, angle_max), p=1.0, border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)),\n",
    "    ])\n",
    "    transformed = transform(image=image)\n",
    "\n",
    "    transformed_image = transformed['image']\n",
    "\n",
    "    # 변환된 이미지를 원본 크기에 맞추고 빈 곳을 흰색으로 채우기\n",
    "    padded_image = pad_resize_and_shift(transformed_image, (h, w), shift_limit=0.1, scale_min=0, scale_max=0)\n",
    "\n",
    "    return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "rotated_image = apply_rotation(image)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB))  \n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오버레이 함수 정의\n",
    "def apply_overlay(image, scale_min, scale_max, angle_min, angle_max, alpha_min, alpha_max):\n",
    "    h, w = image.shape[:2]\n",
    "    symmetric_image = cv2.flip(image, 1) # 1은 좌우 반전, 0은 상하 반전\n",
    "\n",
    "    # 변환된 이미지를 원본 크기에 맞추고 빈 곳을 흰색으로 채우기\n",
    "    padded_image = pad_resize_and_shift(symmetric_image, (h, w), shift_limit=0, scale_min=scale_min, scale_max=scale_max)\n",
    "    # 변환된 이미지를 돌리기\n",
    "    rotate_image = apply_rotation(padded_image,angle_min, angle_max)\n",
    "\n",
    "    alpha = random.uniform(alpha_min, alpha_max) # 이 값은 오버레이할 이미지의 투명도를 결정\n",
    "    overlay_image = cv2.addWeighted(image, 1, rotate_image, alpha, 0)\n",
    "    return overlay_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# ex\n",
    "scale_min = -0.3\n",
    "scale_max = 0.3\n",
    "angle_min = 0\n",
    "angle_max = 360\n",
    "alpha_min = 0.5\n",
    "alpha_max = 1.0\n",
    "\n",
    "overlay_image = apply_overlay(image, scale_min, scale_max, angle_min, angle_max, alpha_min, alpha_max)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(overlay_image, cv2.COLOR_BGR2RGB))  \n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈 추가 함수 정의 (검정 부분 마스킹)\n",
    "def add_random_noise(image_tensor, noise_range=(-0.2, 0)):\n",
    "    noise_std = random.uniform(0.3, 1.0)  # 노이즈 강도 조정 (더 큰 표준 편차 선택)\n",
    "    noise = torch.randn(image_tensor.size(1) // 2, image_tensor.size(2) // 2) * noise_std  # 그레이스케일 노이즈 생성 # (295, 221)\n",
    "    noise = noise.unsqueeze(0).repeat(3, 1, 1)  # 채널 크기 맞추기\n",
    "    noise = F.interpolate(noise.unsqueeze(0), size=(image_tensor.shape[1], image_tensor.shape[2]), mode='bilinear', align_corners=False).squeeze(0)  # 노이즈 크기를 원본 이미지에 맞게 조정 # F.interpolate 함수가 입력 텐서의 차원을 (batch_size, channels, height, width) 형태로 요구\n",
    "    noise = torch.clamp(noise, noise_range[0], noise_range[1])  # 노이즈의 값 범위를 제한 (밝은 회색)\n",
    "\n",
    "    # 검정 부분 마스킹 (RGB가 모두 0인 부분만 마스킹)\n",
    "    mask = (image_tensor.sum(dim=0) != 0).float().unsqueeze(0).repeat(3, 1, 1) # 검정 부분에는 노이즈가 더해지지 않도록\n",
    "    image_tensor = image_tensor + noise * mask  # 노이즈 추가\n",
    "    image_tensor = torch.clamp(image_tensor, 0, 1)  # 값 범위를 0과 1 사이로 클램핑\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "# 이미지 텐서로 변환하고 [0, 1] 범위로 정규화\n",
    "image_tensor = torch.tensor(image / 255.0).float()  # (H, W, C) 형태의 numpy 배열을 텐서로 변환\n",
    "image_tensor = image_tensor.permute(2, 0, 1)  # (C, H, W) \n",
    "\n",
    "noisy_image_tensor = add_random_noise(image_tensor)\n",
    "\n",
    "# 텐서를 다시 이미지 형태로 변환\n",
    "noisy_image = noisy_image_tensor.permute(1, 2, 0).numpy()  # (C, H, W) -> (H, W, C)\n",
    "noisy_image = np.clip(noisy_image, 0, 1)  # 범위를 [0, 1]로 클램핑\n",
    "\n",
    "plt.imshow(noisy_image)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filp(image):\n",
    "    transforms = [\n",
    "        A.HorizontalFlip(p=1), # 좌우반전\n",
    "        A.VerticalFlip(p=1),  # 상하반전\n",
    "        A.Flip(p=1),\n",
    "    ]\n",
    "\n",
    "    transform = A.Compose(random.sample(transforms, random.randint(1, len(transforms)))) # transforms에서 1~3까지 무작위 적용\n",
    "    transformed = transform(image=image)\n",
    "\n",
    "    return transformed['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "rotated_image = apply_filp(image)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB))  \n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 채도 감수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채도 감소 함수 정의\n",
    "def reduce_saturation(image, saturation_factor_range=(0.3, 0.6)):\n",
    "    saturation_factor = random.uniform(*saturation_factor_range) # 채도가 1.0일 경우 원본 이미지와 같고, 0.0이면 완전히 무채색(흑백) 이미지가 됨.\n",
    "    pil_image = TF.to_pil_image(image)  # numpy 배열을 PIL 이미지로 변환\n",
    "    pil_image = TF.adjust_saturation(pil_image, saturation_factor)\n",
    "    return np.array(pil_image)  # PIL 이미지를 numpy 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "rotated_image = reduce_saturation(image)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB))  \n",
    "plt.axis('off')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 밝기 증가 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 밝기 증가 함수 정의\n",
    "def increase_brightness(image_tensor, brightness_increase_range=(0.1, 0.4)):\n",
    "    brightness_increase = random.uniform(*brightness_increase_range)\n",
    "    image_tensor = image_tensor + brightness_increase\n",
    "    image_tensor = torch.clamp(image_tensor, 0, 1)\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/seojeongmin/Desktop/Pytorh-lighting-hydra/data/0a9843bf4ec022f3.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "image_tensor = torch.tensor(image / 255.0).float()  \n",
    "image_tensor = image_tensor.permute(2, 0, 1)  \n",
    "\n",
    "noisy_image_tensor = increase_brightness(image_tensor)\n",
    "\n",
    "noisy_image = noisy_image_tensor.permute(1, 2, 0).numpy()  \n",
    "noisy_image = np.clip(noisy_image, 0, 1)  \n",
    "\n",
    "plt.imshow(noisy_image)\n",
    "plt.axis('off')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augraphy\n",
    "- 빛 번짐\n",
    "- 그림자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빛 번짐 Augraphy 설정\n",
    "reflected_light = ReflectedLight(\n",
    "    reflected_light_smoothness=0, # 빛 번짐의 부드러움을 설정합니다. 0일 경우 경계가 뚜렷하게 나타나고, 값이 클수록 부드러운 경계를 갖게 됩니다.\n",
    "    reflected_light_internal_radius_range=(0.05, 0.1),\n",
    "    reflected_light_external_radius_range=(0.3, 0.3),\n",
    "    reflected_light_minor_major_ratio_range=(0.9, 1.0), # 1.0이면 정원형, 0.9이면 약간 타원형\n",
    "    reflected_light_color=(255, 255, 255), # 빛 번짐의 색상을 설정\n",
    "    reflected_light_internal_max_brightness_range=(0.4, 0.5), # 내부 반지름에서의 최대 밝기 범위를 설정\n",
    "    reflected_light_external_max_brightness_range=(0.2, 0.3), # 외부 반지름에서의 최대 밝기 범위를 설정\n",
    "    reflected_light_location=\"random\", # 빛 번짐의 위치를 무작위로 설정\n",
    "    reflected_light_ellipse_angle_range=(0, 360),\n",
    "    reflected_light_gaussian_kernel_size_range=(330, 330),\n",
    ")\n",
    "\n",
    "# 그림자 Augraphy 설정\n",
    "shadowcast = ShadowCast(\n",
    "    shadow_side=\"bottom\",\n",
    "    shadow_vertices_range=(2, 3),\n",
    "    shadow_width_range=(0.5, 0.8),\n",
    "    shadow_height_range=(0.5, 0.8),\n",
    "    shadow_color=(0, 0, 0),\n",
    "    shadow_opacity_range=(0.5, 0.6),\n",
    "    shadow_iterations_range=(1, 2),\n",
    "    shadow_blur_kernel_range=(101, 301),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random.seed(123)\n",
    "np.random.seed(123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
